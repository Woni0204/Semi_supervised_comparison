{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c7d056",
   "metadata": {},
   "source": [
    "# Check Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6dc29",
   "metadata": {},
   "source": [
    "* Dataset은 PASCALVOC2012.txt 파일에 JPEGImages와 SegmentationClass 하나씩 한줄로 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fdb25f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 개수: 12031\n",
      "중복 데이터 개수: 0\n",
      "중복되는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# 파일을 읽고 각 줄을 리스트에 저장\n",
    "with open('PASCALVOC2012.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 줄바꿈 문자 제거\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "# 중복을 확인하기 위해 set으로 변환\n",
    "unique_lines = set(lines)\n",
    "\n",
    "# 중복되는 값 확인\n",
    "duplicates = [line for line in lines if lines.count(line) > 1]\n",
    "\n",
    "# 결과 출력\n",
    "total_lines = len(lines)\n",
    "unique_lines_count = len(unique_lines)\n",
    "duplicate_count = total_lines - unique_lines_count\n",
    "\n",
    "print(f\"총 데이터 개수: {total_lines}\")\n",
    "print(f\"중복 데이터 개수: {duplicate_count}\")\n",
    "\n",
    "if duplicates:\n",
    "    print(\"중복되는 값이 있습니다:\")\n",
    "    for dup in set(duplicates):\n",
    "        print(dup)\n",
    "else:\n",
    "    print(\"중복되는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707601f",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc031a76",
   "metadata": {},
   "source": [
    "* 해당 데이터를 스플릿하는 과정은 다음과 같습니다. (랜덤 샘플링)\n",
    "1. 10번의 반복 실험 진행을 위해 iter01, iter02, iter03, ... , iter10 순으로 저장됩니다.\n",
    "2. 각 iter 폴더에는 training, test, validation 폴더가 저장됩니다.\n",
    "3. training 폴더에는 labeled 폴더와 unlabeled 폴더와 train.txt 파일이, test 폴더에는 test.txt, validation 폴더에는 valid.txt 가 저장됩니다.\n",
    "4. labeled 폴더에는 레이블 정보를 담는 labeled.txt 파일이, unlabeled 폴더에는 레이블 정보가 없는 unlabeled.txt 파일이 저장됩니다.\n",
    "5. labeled.txt 파일에는 label ratio (1/4, 1/8, 1/16) 에 맞춰 각 파일이 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "344b7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 7218\n",
      "1 : 2407\n",
      "1 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "2 : 7218\n",
      "2 : 2407\n",
      "2 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "3 : 7218\n",
      "3 : 2407\n",
      "3 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "4 : 7218\n",
      "4 : 2407\n",
      "4 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "5 : 7218\n",
      "5 : 2407\n",
      "5 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "6 : 7218\n",
      "6 : 2407\n",
      "6 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "7 : 7218\n",
      "7 : 2407\n",
      "7 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "8 : 7218\n",
      "8 : 2407\n",
      "8 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "9 : 7218\n",
      "9 : 2407\n",
      "9 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n",
      "10 : 7218\n",
      "10 : 2407\n",
      "10 : 2406\n",
      "Train file: 7218 lines\n",
      "Test file: 2407 lines\n",
      "Validation file: 2406 lines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# 기본 설정\n",
    "iterations = 10\n",
    "label_ratios = [1/4, 1/8, 1/16]\n",
    "random_seed = 42\n",
    "\n",
    "# 전체 데이터 파일 리스트 읽기\n",
    "with open('PASCALVOC2012.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 총 데이터 개수\n",
    "total_data_count = len(lines)\n",
    "\n",
    "# 비율 설정 (정수로 개수 계산)\n",
    "train_ratio = 0.6\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_count = int(total_data_count * train_ratio)\n",
    "valid_count = int(total_data_count * valid_ratio)\n",
    "test_count = total_data_count - train_count - valid_count  # 나머지를 test로 할당\n",
    "\n",
    "for i in range(1, iterations + 1):\n",
    "    random.seed(random_seed)  # 시드 고정\n",
    "    random.shuffle(lines)  # 데이터 셔플\n",
    "\n",
    "    iter_dir = f'iter{i:02d}'\n",
    "    \n",
    "    # 데이터를 train, valid, test로 분할\n",
    "    train_data = lines[:train_count]\n",
    "    valid_data = lines[train_count:train_count + valid_count]\n",
    "    test_data = lines[train_count + valid_count:]\n",
    "    print(f'{i} : {len(train_data)}')\n",
    "    print(f'{i} : {len(test_data)}')\n",
    "    print(f'{i} : {len(valid_data)}')\n",
    "\n",
    "    # 각 폴더 생성\n",
    "    os.makedirs(os.path.join(iter_dir, 'training'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(iter_dir, 'test'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(iter_dir, 'validation'), exist_ok=True)\n",
    "\n",
    "    # train.txt, test.txt, valid.txt 생성 후 각 파일에 몇 개의 라인이 기록되었는지 확인\n",
    "    with open(os.path.join(iter_dir, 'training', 'train.txt'), 'w') as f:\n",
    "        f.writelines([line if line.endswith('\\n') else line + '\\n' for line in train_data])\n",
    "    \n",
    "    with open(os.path.join(iter_dir, 'test', 'test.txt'), 'w') as f:\n",
    "        f.writelines([line if line.endswith('\\n') else line + '\\n' for line in test_data])\n",
    "    \n",
    "    with open(os.path.join(iter_dir, 'validation', 'valid.txt'), 'w') as f:\n",
    "        f.writelines([line if line.endswith('\\n') else line + '\\n' for line in valid_data])\n",
    "    \n",
    "    # 라인 수 확인\n",
    "    with open(os.path.join(iter_dir, 'training', 'train.txt'), 'r') as f:\n",
    "        train_lines_written = len(f.readlines())\n",
    "    with open(os.path.join(iter_dir, 'test', 'test.txt'), 'r') as f:\n",
    "        test_lines_written = len(f.readlines())\n",
    "    with open(os.path.join(iter_dir, 'validation', 'valid.txt'), 'r') as f:\n",
    "        valid_lines_written = len(f.readlines())\n",
    "    \n",
    "    print(f'Train file: {train_lines_written} lines')\n",
    "    print(f'Test file: {test_lines_written} lines')\n",
    "    print(f'Validation file: {valid_lines_written} lines')\n",
    "\n",
    "    \n",
    "    # 라벨 비율에 따른 데이터 분할\n",
    "    for ratio in label_ratios:\n",
    "        ratio_name = f'1_{int(1/ratio)}'\n",
    "        labeled_count = int(train_count * ratio)\n",
    "        unlabeled_count = train_count - labeled_count\n",
    "        \n",
    "        ratio_dir = os.path.join(iter_dir, 'training', ratio_name)\n",
    "        os.makedirs(os.path.join(ratio_dir, 'labeled'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(ratio_dir, 'unlabeled'), exist_ok=True)\n",
    "\n",
    "        labeled_data = train_data[:labeled_count]\n",
    "        unlabeled_data = train_data[labeled_count:]\n",
    "\n",
    "        # labeled.txt, unlabeled.txt 생성\n",
    "        with open(os.path.join(ratio_dir, 'labeled', 'labeled.txt'), 'w') as f:\n",
    "            f.writelines([line if line.endswith('\\n') else line + '\\n' for line in labeled_data])\n",
    "        with open(os.path.join(ratio_dir, 'unlabeled', 'unlabeled.txt'), 'w') as f:\n",
    "            f.writelines([line if line.endswith('\\n') else line + '\\n' for line in unlabeled_data])\n",
    "\n",
    "    # 시드 증가\n",
    "    random_seed += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b542ea",
   "metadata": {},
   "source": [
    "# Data Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52f8d1",
   "metadata": {},
   "source": [
    "* 해당 데이터의 검증 절차는 다음과 같습니다.\n",
    "1. 각 iter에서 생성된 train.txt, test.txt, valid.txt가 다음 생성되는 train.txt, test.txt, valid.txt와 같은지의 여부를 판별합니다. (데이터 셔플되었는지 확인)\n",
    "2. 각 iter에서 생성된 train.txt, test.txt, valid.txt의 데이터 개수가 같은지 확인합니다.\n",
    "3. label ratio대로 구분한 labeled.txt, unlabeled.txt의 개수가 진행되었는지 확인합니다.\n",
    "4. label ratio대로 구분한 labeled.txt, unlabeled.txt가 같은지의 여부를 판별합니다. (데이터 셔플되었는지 확인)\n",
    "5. train.txt, test.txt, valid.txt를 합친 모든 데이터의 개수가 기존 데이터 개수(12030개)와 일치하는지 확인합니다.\n",
    "6. train.txt, test.txt, valid.txt를 합친 데이터에서 중복이 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cb4da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, train: 7218 lines\n",
      "Iteration 1, test: 2407 lines\n",
      "Iteration 1, valid: 2406 lines\n",
      "Iteration 1, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 1, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 1, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 2, train: 7218 lines\n",
      "Iteration 2, test: 2407 lines\n",
      "Iteration 2, valid: 2406 lines\n",
      "Iteration 2, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 2, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 2, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 3, train: 7218 lines\n",
      "Iteration 3, test: 2407 lines\n",
      "Iteration 3, valid: 2406 lines\n",
      "Iteration 3, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 3, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 3, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 4, train: 7218 lines\n",
      "Iteration 4, test: 2407 lines\n",
      "Iteration 4, valid: 2406 lines\n",
      "Iteration 4, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 4, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 4, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 5, train: 7218 lines\n",
      "Iteration 5, test: 2407 lines\n",
      "Iteration 5, valid: 2406 lines\n",
      "Iteration 5, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 5, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 5, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 6, train: 7218 lines\n",
      "Iteration 6, test: 2407 lines\n",
      "Iteration 6, valid: 2406 lines\n",
      "Iteration 6, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 6, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 6, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 7, train: 7218 lines\n",
      "Iteration 7, test: 2407 lines\n",
      "Iteration 7, valid: 2406 lines\n",
      "Iteration 7, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 7, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 7, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 8, train: 7218 lines\n",
      "Iteration 8, test: 2407 lines\n",
      "Iteration 8, valid: 2406 lines\n",
      "Iteration 8, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 8, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 8, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 9, train: 7218 lines\n",
      "Iteration 9, test: 2407 lines\n",
      "Iteration 9, valid: 2406 lines\n",
      "Iteration 9, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 9, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 9, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n",
      "Iteration 10, train: 7218 lines\n",
      "Iteration 10, test: 2407 lines\n",
      "Iteration 10, valid: 2406 lines\n",
      "Iteration 10, Ratio 1_4, Labeled: 1804 lines, Unlabeled: 5414 lines\n",
      "Iteration 10, Ratio 1_8, Labeled: 902 lines, Unlabeled: 6316 lines\n",
      "Iteration 10, Ratio 1_16, Labeled: 451 lines, Unlabeled: 6767 lines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 기본 설정\n",
    "iterations = 10\n",
    "label_ratios = [1/4, 1/8, 1/16]\n",
    "\n",
    "# 각 iteration 및 비율별 데이터 개수 출력\n",
    "for i in range(1, iterations + 1):\n",
    "    iter_dir = f'iter{i:02d}'\n",
    "    \n",
    "    # Train, Test, Validation 파일의 데이터 개수 출력\n",
    "    for split in ['train', 'test', 'valid']:\n",
    "        file_name = f'{split}.txt'\n",
    "        if split == 'valid':\n",
    "            file_name = 'valid.txt'  # validation 파일 이름은 valid.txt로 저장됨\n",
    "        file_path = os.path.join(iter_dir, 'training' if split == 'train' else 'test' if split == 'test' else 'validation', file_name)\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            line_count = len(f.readlines())\n",
    "        print(f'Iteration {i}, {split}: {line_count} lines')\n",
    "    \n",
    "    # 라벨 비율에 따른 파일의 데이터 개수 출력\n",
    "    for ratio in label_ratios:\n",
    "        ratio_dir = os.path.join(iter_dir, 'training', f'1_{int(1/ratio)}')\n",
    "        labeled_dir = os.path.join(ratio_dir, 'labeled')\n",
    "        unlabeled_dir = os.path.join(ratio_dir, 'unlabeled')\n",
    "        \n",
    "        labeled_file = os.path.join(labeled_dir, 'labeled.txt')\n",
    "        unlabeled_file = os.path.join(unlabeled_dir, 'unlabeled.txt')\n",
    "        \n",
    "        with open(labeled_file, 'r') as f:\n",
    "            labeled_count = len(f.readlines())\n",
    "        \n",
    "        with open(unlabeled_file, 'r') as f:\n",
    "            unlabeled_count = len(f.readlines())\n",
    "        \n",
    "        print(f'Iteration {i}, Ratio 1_{int(1/ratio)}, Labeled: {labeled_count} lines, Unlabeled: {unlabeled_count} lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7b4de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter01/training/train.txt and iter02/training/train.txt are different as expected.\n",
      "iter01/test/test.txt and iter02/test/test.txt are different as expected.\n",
      "iter01/validation/valid.txt and iter02/validation/valid.txt are different as expected.\n",
      "Line counts in iter01 and iter02 are the same.\n",
      "iter01\\training\\1_4\\labeled\\labeled.txt and iter02\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter01\\training\\1_4\\unlabeled\\unlabeled.txt and iter02\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter01\\training\\1_8\\labeled\\labeled.txt and iter02\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter01\\training\\1_8\\unlabeled\\unlabeled.txt and iter02\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter01\\training\\1_16\\labeled\\labeled.txt and iter02\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter01\\training\\1_16\\unlabeled\\unlabeled.txt and iter02\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter01 total data count matches the expected 12031.\n",
      "iter02 total data count matches the expected 12031.\n",
      "iter01 combined data contains no duplicates.\n",
      "iter02 combined data contains no duplicates.\n",
      "iter02/training/train.txt and iter03/training/train.txt are different as expected.\n",
      "iter02/test/test.txt and iter03/test/test.txt are different as expected.\n",
      "iter02/validation/valid.txt and iter03/validation/valid.txt are different as expected.\n",
      "Line counts in iter02 and iter03 are the same.\n",
      "iter02\\training\\1_4\\labeled\\labeled.txt and iter03\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter02\\training\\1_4\\unlabeled\\unlabeled.txt and iter03\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter02\\training\\1_8\\labeled\\labeled.txt and iter03\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter02\\training\\1_8\\unlabeled\\unlabeled.txt and iter03\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter02\\training\\1_16\\labeled\\labeled.txt and iter03\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter02\\training\\1_16\\unlabeled\\unlabeled.txt and iter03\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter02 total data count matches the expected 12031.\n",
      "iter03 total data count matches the expected 12031.\n",
      "iter02 combined data contains no duplicates.\n",
      "iter03 combined data contains no duplicates.\n",
      "iter03/training/train.txt and iter04/training/train.txt are different as expected.\n",
      "iter03/test/test.txt and iter04/test/test.txt are different as expected.\n",
      "iter03/validation/valid.txt and iter04/validation/valid.txt are different as expected.\n",
      "Line counts in iter03 and iter04 are the same.\n",
      "iter03\\training\\1_4\\labeled\\labeled.txt and iter04\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter03\\training\\1_4\\unlabeled\\unlabeled.txt and iter04\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter03\\training\\1_8\\labeled\\labeled.txt and iter04\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter03\\training\\1_8\\unlabeled\\unlabeled.txt and iter04\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter03\\training\\1_16\\labeled\\labeled.txt and iter04\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter03\\training\\1_16\\unlabeled\\unlabeled.txt and iter04\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter03 total data count matches the expected 12031.\n",
      "iter04 total data count matches the expected 12031.\n",
      "iter03 combined data contains no duplicates.\n",
      "iter04 combined data contains no duplicates.\n",
      "iter04/training/train.txt and iter05/training/train.txt are different as expected.\n",
      "iter04/test/test.txt and iter05/test/test.txt are different as expected.\n",
      "iter04/validation/valid.txt and iter05/validation/valid.txt are different as expected.\n",
      "Line counts in iter04 and iter05 are the same.\n",
      "iter04\\training\\1_4\\labeled\\labeled.txt and iter05\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter04\\training\\1_4\\unlabeled\\unlabeled.txt and iter05\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter04\\training\\1_8\\labeled\\labeled.txt and iter05\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter04\\training\\1_8\\unlabeled\\unlabeled.txt and iter05\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter04\\training\\1_16\\labeled\\labeled.txt and iter05\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter04\\training\\1_16\\unlabeled\\unlabeled.txt and iter05\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter04 total data count matches the expected 12031.\n",
      "iter05 total data count matches the expected 12031.\n",
      "iter04 combined data contains no duplicates.\n",
      "iter05 combined data contains no duplicates.\n",
      "iter05/training/train.txt and iter06/training/train.txt are different as expected.\n",
      "iter05/test/test.txt and iter06/test/test.txt are different as expected.\n",
      "iter05/validation/valid.txt and iter06/validation/valid.txt are different as expected.\n",
      "Line counts in iter05 and iter06 are the same.\n",
      "iter05\\training\\1_4\\labeled\\labeled.txt and iter06\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter05\\training\\1_4\\unlabeled\\unlabeled.txt and iter06\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter05\\training\\1_8\\labeled\\labeled.txt and iter06\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter05\\training\\1_8\\unlabeled\\unlabeled.txt and iter06\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter05\\training\\1_16\\labeled\\labeled.txt and iter06\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter05\\training\\1_16\\unlabeled\\unlabeled.txt and iter06\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter05 total data count matches the expected 12031.\n",
      "iter06 total data count matches the expected 12031.\n",
      "iter05 combined data contains no duplicates.\n",
      "iter06 combined data contains no duplicates.\n",
      "iter06/training/train.txt and iter07/training/train.txt are different as expected.\n",
      "iter06/test/test.txt and iter07/test/test.txt are different as expected.\n",
      "iter06/validation/valid.txt and iter07/validation/valid.txt are different as expected.\n",
      "Line counts in iter06 and iter07 are the same.\n",
      "iter06\\training\\1_4\\labeled\\labeled.txt and iter07\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter06\\training\\1_4\\unlabeled\\unlabeled.txt and iter07\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter06\\training\\1_8\\labeled\\labeled.txt and iter07\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter06\\training\\1_8\\unlabeled\\unlabeled.txt and iter07\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter06\\training\\1_16\\labeled\\labeled.txt and iter07\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter06\\training\\1_16\\unlabeled\\unlabeled.txt and iter07\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter06 total data count matches the expected 12031.\n",
      "iter07 total data count matches the expected 12031.\n",
      "iter06 combined data contains no duplicates.\n",
      "iter07 combined data contains no duplicates.\n",
      "iter07/training/train.txt and iter08/training/train.txt are different as expected.\n",
      "iter07/test/test.txt and iter08/test/test.txt are different as expected.\n",
      "iter07/validation/valid.txt and iter08/validation/valid.txt are different as expected.\n",
      "Line counts in iter07 and iter08 are the same.\n",
      "iter07\\training\\1_4\\labeled\\labeled.txt and iter08\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter07\\training\\1_4\\unlabeled\\unlabeled.txt and iter08\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter07\\training\\1_8\\labeled\\labeled.txt and iter08\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter07\\training\\1_8\\unlabeled\\unlabeled.txt and iter08\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter07\\training\\1_16\\labeled\\labeled.txt and iter08\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter07\\training\\1_16\\unlabeled\\unlabeled.txt and iter08\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter07 total data count matches the expected 12031.\n",
      "iter08 total data count matches the expected 12031.\n",
      "iter07 combined data contains no duplicates.\n",
      "iter08 combined data contains no duplicates.\n",
      "iter08/training/train.txt and iter09/training/train.txt are different as expected.\n",
      "iter08/test/test.txt and iter09/test/test.txt are different as expected.\n",
      "iter08/validation/valid.txt and iter09/validation/valid.txt are different as expected.\n",
      "Line counts in iter08 and iter09 are the same.\n",
      "iter08\\training\\1_4\\labeled\\labeled.txt and iter09\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter08\\training\\1_4\\unlabeled\\unlabeled.txt and iter09\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter08\\training\\1_8\\labeled\\labeled.txt and iter09\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter08\\training\\1_8\\unlabeled\\unlabeled.txt and iter09\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter08\\training\\1_16\\labeled\\labeled.txt and iter09\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter08\\training\\1_16\\unlabeled\\unlabeled.txt and iter09\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter08 total data count matches the expected 12031.\n",
      "iter09 total data count matches the expected 12031.\n",
      "iter08 combined data contains no duplicates.\n",
      "iter09 combined data contains no duplicates.\n",
      "iter09/training/train.txt and iter10/training/train.txt are different as expected.\n",
      "iter09/test/test.txt and iter10/test/test.txt are different as expected.\n",
      "iter09/validation/valid.txt and iter10/validation/valid.txt are different as expected.\n",
      "Line counts in iter09 and iter10 are the same.\n",
      "iter09\\training\\1_4\\labeled\\labeled.txt and iter10\\training\\1_4\\labeled\\labeled.txt are different as expected.\n",
      "iter09\\training\\1_4\\unlabeled\\unlabeled.txt and iter10\\training\\1_4\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter09\\training\\1_8\\labeled\\labeled.txt and iter10\\training\\1_8\\labeled\\labeled.txt are different as expected.\n",
      "iter09\\training\\1_8\\unlabeled\\unlabeled.txt and iter10\\training\\1_8\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter09\\training\\1_16\\labeled\\labeled.txt and iter10\\training\\1_16\\labeled\\labeled.txt are different as expected.\n",
      "iter09\\training\\1_16\\unlabeled\\unlabeled.txt and iter10\\training\\1_16\\unlabeled\\unlabeled.txt are different as expected.\n",
      "iter09 total data count matches the expected 12031.\n",
      "iter10 total data count matches the expected 12031.\n",
      "iter09 combined data contains no duplicates.\n",
      "iter10 combined data contains no duplicates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import filecmp\n",
    "\n",
    "# 기본 설정\n",
    "iterations = 10\n",
    "total_data_count = 12031\n",
    "label_ratios = [1/4, 1/8, 1/16]\n",
    "\n",
    "# 1. 각 iter에서 생성된 train.txt, test.txt, valid.txt가 다른지 확인\n",
    "def check_file_difference(iter_dir1, iter_dir2, filenames):\n",
    "    for filename in filenames:\n",
    "        file1 = os.path.join(iter_dir1, filename)\n",
    "        file2 = os.path.join(iter_dir2, filename)\n",
    "        if filecmp.cmp(file1, file2, shallow=False):\n",
    "            print(f\"Error: {iter_dir1}/{filename} and {iter_dir2}/{filename} are the same.\")\n",
    "        else:\n",
    "            print(f\"{iter_dir1}/{filename} and {iter_dir2}/{filename} are different as expected.\")\n",
    "\n",
    "# 2. 각 iter에서 생성된 train.txt, test.txt, valid.txt의 데이터 개수 확인\n",
    "def check_file_line_counts(iter_dir, filenames):\n",
    "    line_counts = {}\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(iter_dir, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            line_counts[filename] = len(f.readlines())\n",
    "    return line_counts\n",
    "\n",
    "# 3. label ratio대로 구분한 labeled.txt, unlabeled.txt의 데이터가 서로 다른지 확인\n",
    "def check_labeled_unlabeled_difference(iter_dir1, iter_dir2, ratio_dirs):\n",
    "    for ratio_dir in ratio_dirs:\n",
    "        labeled_file1 = os.path.join(ratio_dir.replace(iter_dir2, iter_dir1), 'labeled', 'labeled.txt')\n",
    "        labeled_file2 = os.path.join(ratio_dir, 'labeled', 'labeled.txt')\n",
    "        unlabeled_file1 = os.path.join(ratio_dir.replace(iter_dir2, iter_dir1), 'unlabeled', 'unlabeled.txt')\n",
    "        unlabeled_file2 = os.path.join(ratio_dir, 'unlabeled', 'unlabeled.txt')\n",
    "        if filecmp.cmp(labeled_file1, labeled_file2, shallow=False):\n",
    "            print(f\"Error: {labeled_file1} and {labeled_file2} are the same.\")\n",
    "        else:\n",
    "            print(f\"{labeled_file1} and {labeled_file2} are different as expected.\")\n",
    "        if filecmp.cmp(unlabeled_file1, unlabeled_file2, shallow=False):\n",
    "            print(f\"Error: {unlabeled_file1} and {unlabeled_file2} are the same.\")\n",
    "        else:\n",
    "            print(f\"{unlabeled_file1} and {unlabeled_file2} are different as expected.\")\n",
    "\n",
    "# 4. train.txt, test.txt, valid.txt를 합친 모든 데이터의 개수가 기존 데이터 개수(12031개)와 일치하는지 확인\n",
    "def check_total_data_count(iter_dir, filenames):\n",
    "    total_count = 0\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(iter_dir, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            total_count += len(f.readlines())\n",
    "    if total_count != total_data_count:\n",
    "        print(f\"Error: {iter_dir} total data count is {total_count}, expected {total_data_count}.\")\n",
    "    else:\n",
    "        print(f\"{iter_dir} total data count matches the expected {total_data_count}.\")\n",
    "\n",
    "# 5. train.txt, test.txt, valid.txt를 합친 데이터에서 중복이 있는지 확인\n",
    "def check_for_duplicates(iter_dir, filenames):\n",
    "    combined_data = set()\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(iter_dir, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            if len(set(lines)) != len(lines):\n",
    "                print(f\"Error: {iter_dir}/{filename} contains duplicates.\")\n",
    "            combined_data.update(lines)\n",
    "    if len(combined_data) != total_data_count:\n",
    "        print(f\"Error: {iter_dir} combined data contains duplicates.\")\n",
    "    else:\n",
    "        print(f\"{iter_dir} combined data contains no duplicates.\")\n",
    "\n",
    "# 검증 시작\n",
    "train_test_valid_files = ['training/train.txt', 'test/test.txt', 'validation/valid.txt']\n",
    "\n",
    "for i in range(1, iterations):\n",
    "    iter_dir1 = f'iter{i:02d}'\n",
    "    iter_dir2 = f'iter{i+1:02d}'\n",
    "\n",
    "    # 1. 파일 차이점 확인\n",
    "    check_file_difference(iter_dir1, iter_dir2, train_test_valid_files)\n",
    "    \n",
    "    # 2. 라인 개수 확인\n",
    "    counts1 = check_file_line_counts(iter_dir1, train_test_valid_files)\n",
    "    counts2 = check_file_line_counts(iter_dir2, train_test_valid_files)\n",
    "    if counts1 != counts2:\n",
    "        print(f\"Error: Line counts in {iter_dir1} and {iter_dir2} are different.\")\n",
    "    else:\n",
    "        print(f\"Line counts in {iter_dir1} and {iter_dir2} are the same.\")\n",
    "    \n",
    "    # 3. 라벨 데이터 셔플 확인 (labeled/unlabeled 파일 간의 데이터 차이점 확인)\n",
    "    ratio_dirs2 = [os.path.join(iter_dir2, 'training', f'1_{int(1/ratio)}') for ratio in label_ratios]\n",
    "    check_labeled_unlabeled_difference(iter_dir1, iter_dir2, ratio_dirs2)\n",
    "    \n",
    "    # 4. 전체 데이터 개수 확인\n",
    "    check_total_data_count(iter_dir1, train_test_valid_files)\n",
    "    check_total_data_count(iter_dir2, train_test_valid_files)\n",
    "    \n",
    "    # 5. 중복 확인\n",
    "    check_for_duplicates(iter_dir1, train_test_valid_files)\n",
    "    check_for_duplicates(iter_dir2, train_test_valid_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fe961-defa-4753-84d2-8950340804bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
